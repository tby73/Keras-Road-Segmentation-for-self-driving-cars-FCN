{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "from keras import layers, losses, utils, optimizers, callbacks, metrics\n",
    "from keras.applications import VGG16\n",
    "from keras.preprocessing import image\n",
    "from tqdm import tqdm\n",
    "from base64 import b64encode"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get KITTI dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data\n",
    "TRAIN_DATA_DIR = \"/input/kittiroadsegmentation/training/image_2/\"\n",
    "\n",
    "# ground trouth segmentation\n",
    "TRAIN_GT_DIR = \"/input/kittiroadsegmentation/training/gt_image_2/\"\n",
    "\n",
    "# test data\n",
    "TEST_DATA_DIR = \"/input/kittiroadsegmentation/testing/\"\n",
    "\n",
    "# get size of training samples\n",
    "TRAINSET_SIZE = int(len(os.listdir(TRAIN_DATA_DIR)) * 0.8)\n",
    "VALIDATION_SIZE = int(len(os.listdir(TRAIN_DATA_DIR)) * 0.1)\n",
    "TESTSET_SIZE = int(len(os.listdir(TRAIN_DATA_DIR)) - TRAINSET_SIZE - VALIDATION_SIZE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants & Hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 128\n",
    "N_CHANNELS = 3\n",
    "N_CLASSES = 1\n",
    "SEED = 123\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "BUFFER_SIZE = 1000\n",
    "AUTOTUNE = tf.data.AUTOTUNE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parse data into masks and images as a dict, generation of dataset splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ParseImages(image_path: str) -> dict:\n",
    "    # read standard road images and decoding\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.convert_image_dtype(image, tf.uint8)\n",
    "\n",
    "    # three types of image paths: (um_road, umm_road, uu_road)\n",
    "    mask_path = tf.strings.regex_replace(image_path, \"image_2\", \"gt_image_2\")\n",
    "    mask_path = tf.strings.regex_replace(mask_path, \"um_\", \"um_road_\")\n",
    "    mask_path = tf.strings.regex_replace(mask_path, \"umm_\", \"umm_road_\")\n",
    "    mask_path = tf.strings.regex_replace(mask_path, \"uu_\", \"uu_road_\")\n",
    "\n",
    "    # read and decode masks\n",
    "    mask = tf.io.read_file(mask_path)\n",
    "    mask = tf.image.decode_png(mask, channels=3)\n",
    "\n",
    "    # labeling\n",
    "    non_road_label = np.array([255, 0, 0])\n",
    "    road_label = np.array([255, 0, 255])\n",
    "    other_road_label = np.array([0, 0, 0])\n",
    "\n",
    "    # convert mask to binary\n",
    "    mask = tf.experimental.numpy.all(mask == road_label, axis=2)\n",
    "    mask = tf.cast(mask, tf.uint8)\n",
    "    mask = tf.expand_dims(mask, axis=-1)\n",
    "\n",
    "    return { \"image\": image, \"segmentation_mask\": mask}\n",
    "\n",
    "# generate dataset splits: test, train, val\n",
    "dataset = tf.data.Dataset.list_files(TRAIN_DATA_DIR + \"*.png\", seed=SEED)\n",
    "dataset = dataset.map(ParseImages)\n",
    "\n",
    "# splitting\n",
    "train_ds = dataset.take(TRAINSET_SIZE + VALIDATION_SIZE)\n",
    "validation_ds = train_ds.skip(TRAINSET_SIZE)\n",
    "train_ds = train_ds.take(TRAINSET_SIZE)\n",
    "test_ds = dataset.skip(TRAINSET_SIZE - VALIDATION_SIZE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing and Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def Normalize(input_image, input_mask) -> tuple:\n",
    "    input_image = tf.cast(input_image, tf.float32) / 255.0\n",
    "    return input_image, input_mask\n",
    "\n",
    "@tf.function\n",
    "def LoadTrainImages(datapoint) -> tuple:\n",
    "    # resize images and masks\n",
    "    input_image = tf.image.resize(datapoint[\"image\"], (IMG_SIZE, IMG_SIZE))\n",
    "    input_mask = tf.image.resize(datapoint[\"segmentation_mask\"], (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "    # data augmentation by randomly flipping the image and generate new training data\n",
    "    if tf.random.uniform() > 0.5:\n",
    "        input_image = tf.image.flip_left_right(input_image)\n",
    "        input_mask = tf.image.flip_left_right(input_mask)\n",
    "\n",
    "    # normalize images\n",
    "    input_image, input_mask = Normalize(input_image, input_mask)\n",
    "\n",
    "    return input_image, input_mask\n",
    "\n",
    "@tf.function\n",
    "def LoadTestImages(datapoint: dict) -> tuple:\n",
    "    # resizing\n",
    "    input_image = tf.image.resize(datapoint['image'], (IMG_SIZE, IMG_SIZE))\n",
    "    input_mask = tf.image.resize(datapoint['segmentation_mask'], (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "    # normalizing\n",
    "    input_image, input_mask = Normalize(input_image, input_mask)\n",
    "\n",
    "    return input_image, input_mask\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process training and testing data for performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full ds dict\n",
    "dataset = { \"train\": train_ds, \"test\": test_ds, \"val\": validation_ds }\n",
    "\n",
    "# processing training data\n",
    "dataset[\"train\"] = dataset[\"train\"].map(LoadTrainImages, num_parallel_calls=AUTOTUNE)\n",
    "dataset[\"train\"] = dataset[\"train\"].shuffle(buffer_size=BUFFER_SIZE, seed=SEED).repeat().batch(BATCH_SIZE)\n",
    "dataset[\"train\"] = dataset[\"train\"].prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "# processing test data\n",
    "dataset[\"test\"] = dataset[\"test\"].map(LoadTestImages).batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "# processing validation data\n",
    "dataset[\"val\"] = dataset[\"val\"].map(LoadTestImages)\n",
    "dataset[\"val\"] = dataset[\"val\"].repeat().batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "print(dataset[\"train\"])\n",
    "print(dataset[\"test\"])\n",
    "print(dataset[\"val\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display some dataset samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DisplaySamples(display_list):\n",
    "    plt.figure(figsize=(18, 18))\n",
    "\n",
    "    # display info\n",
    "    titles = [\"Input Image\", \"True Segmentation\", \"Model Prediction\"]\n",
    "\n",
    "    # plot images from list\n",
    "    for i in range(len(display_list)):\n",
    "        plt.subplot(1, len(display_list), i + 1)\n",
    "        plt.title(titles[i])\n",
    "        plt.imshow(utils.array_to_img(display_list[i]))\n",
    "        \n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, mask in dataset[\"train\"].take(1):\n",
    "    sample_image, sample_mask = image, mask\n",
    "\n",
    "DisplaySamples([sample_image[0], sample_mask[0]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the FCN Road Segmentation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_model = VGG16()\n",
    "vgg16_model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input Shape for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE = (IMG_SIZE, IMG_SIZE, N_CHANNELS)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RoadSegmentationModel():\n",
    "    # input layer\n",
    "    inputs = layers.Input(INPUT_SHAPE)\n",
    "\n",
    "    # get VGG16 model\n",
    "    vgg16_model = VGG16(include_top=False, weights=\"imagenet\", input_tensor=inputs)\n",
    "\n",
    "    # encoder \n",
    "    c1 = vgg16_model.get_layer(\"block3_pool\").output\n",
    "    c2 = vgg16_model.get_layer(\"block4_pool\").output\n",
    "    c3 = vgg16_model.get_layer(\"block4_pool\").output\n",
    "\n",
    "    # decoder\n",
    "    u1 = layers.UpSampling2D((2, 2), interpolation=\"bilinear\")(c3)\n",
    "    ct1 = layers.Concatenate()([u1, c2])\n",
    "    u2 = layers.UpSampling2D((2, 2), interpolation=\"bilinear\")(ct1)\n",
    "    ct2 = layers.Concatenate()([u2, ct1])\n",
    "\n",
    "    # final upsampling\n",
    "    u3 = layers.UpSampling2D((8, 8), interpolation=\"bilinear\")(ct2)\n",
    "\n",
    "    # get outputs\n",
    "    outputs = layers.Conv2D(N_CLASSES, 1, activation=\"sigmoid\")(u3)\n",
    "\n",
    "    # build model\n",
    "    return keras.Model(inputs, outputs, name=\"RDS_FCN\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compling & Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_iou = metrics.MeanIoU(2)\n",
    "segmentation_model = RoadSegmentationModel()\n",
    "\n",
    "segmentation_model.compile(optimizer=optimizers.Adam(), loss=losses.BinaryCrossentropy(), metrics=[mean_iou])\n",
    "utils.plot_model(segmentation_model, show_shapes=True)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
